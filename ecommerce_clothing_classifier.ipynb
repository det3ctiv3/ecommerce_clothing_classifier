{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZynVXY9skaRt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchmetrics import Accuracy, Precision, Recall\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZV4f3c9kbTd",
        "outputId": "bf105583-e892-4aa0-9184-bc84818ae3ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 113MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.98MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 59.4MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GHRAp1Jkc-W",
        "outputId": "1b2acb6c-2dad-4204-fa61-8058b537bf58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULr1WoOCkgVN",
        "outputId": "3af1d4ad-a657-4f1f-c8ca-482ad423bf1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image, sample_label = train_data[0]\n",
        "print(f\" Sample image shape: {sample_image.shape}\")\n",
        "print(f\" Sample label type: {type(sample_label)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_kW0x07khp_",
        "outputId": "cf269fcf-dbbc-4791-a747-37c71bdf5d2e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sample image shape: torch.Size([1, 28, 28])\n",
            " Sample label type: <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train data classes {train_data.classes}\")\n",
        "print(f\"Train data length {len(train_data.classes)}\")\n",
        "classes = train_data.classes\n",
        "num_classes = len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymGvhKcEkilz",
        "outputId": "5c02615a-5ab3-49d2-db55-77f522411ab0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data classes ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
            "Train data length 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_input_channels = 1\n",
        "num_output_channels = 16\n",
        "image_size = train_data[0][0].shape[1]\n",
        "print(image_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKcQ5MYZklbg",
        "outputId": "66941d43-d9e2-452a-e869-0f647dd6fd2d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClothesClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ClothesClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size = 3, stride = 1, padding =1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(num_output_channels * (image_size // 2) ** 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    train_data,\n",
        "    batch_size = 10,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "def train_model(optimizer, net, num_epochs):\n",
        "    num_processed = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0\n",
        "        num_processed = 0\n",
        "\n",
        "        for features, labels in dataloader_train:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            num_processed += len(labels)\n",
        "        print(f\"epoch {epoch}, loss: {running_loss / num_processed}\")\n",
        "\n",
        "        train_loss = running_loss / len(dataloader_train)"
      ],
      "metadata": {
        "id": "B5k4IUxrkony"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ClothesClassifier(num_classes)\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
        "\n",
        "train_model(\n",
        "    optimizer = optimizer,\n",
        "    net = net,\n",
        "    num_epochs = 1,\n",
        "    )\n",
        "\n",
        "dataloader_test = DataLoader(\n",
        "    test_data,\n",
        "    batch_size = 10,\n",
        "    shuffle = False\n",
        "    )\n",
        "\n",
        "accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "precision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\n",
        "recall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n",
        "\n",
        "net.eval()\n",
        "predictions = []\n",
        "for i, (features, labels) in enumerate(dataloader_test):\n",
        "    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n",
        "    cat = torch.argmax(output, dim=-1)\n",
        "    predictions.extend(cat.tolist())\n",
        "    accuracy_metric(cat, labels)\n",
        "    precision_metric(cat, labels)\n",
        "    recall_metric(cat, labels)\n",
        "\n",
        "accuracy = accuracy_metric.compute().item()\n",
        "precision = precision_metric.compute().tolist()\n",
        "recall = recall_metric.compute().tolist()\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision (per class):', precision)\n",
        "print('Recall (per class):', recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4ERQQ9tkpVv",
        "outputId": "8456c32f-73c0-41ab-d6c1-acc226f9d1f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss: 0.039598041016639524\n",
            "Accuracy: 0.8823999762535095\n",
            "Precision (per class): [0.8662131428718567, 0.9937888383865356, 0.8171091675758362, 0.820244312286377, 0.8344017267227173, 0.961614191532135, 0.6610487103462219, 0.9317963719367981, 0.983589768409729, 0.9821615815162659]\n",
            "Recall (per class): [0.7639999985694885, 0.9599999785423279, 0.8309999704360962, 0.9399999976158142, 0.781000018119812, 0.9769999980926514, 0.7059999704360962, 0.9700000286102295, 0.9589999914169312, 0.9359999895095825]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hnjEG68ekzvr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}